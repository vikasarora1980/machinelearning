---
title: "Qualitative Assessment of Weight Lifting Exercise"
author: "Vikas"
date: "April 24, 2016"
output: html_document
---

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

Given data from accelerometers, the goal is to predict the class of action which is one of the following.

A. Exactly as per the specifications.
B. Throwing elbows to the front.
C. Lifting the dumbbell only halfway.
D. Lowering the dumbbell only halfway.
E. Throwing the hips to the front.

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes." 

## Analysis

Prediction evaluations will be based on maximizing the accuracy and minimizing the out-of-sample error. All other available variables after cleaning will be used for prediction.

Two models will be tested using decision tree and random forest algorithms. The model with the highest accuracy will be chosen as our final model.

Cross-validation will be performed by subsampling our training data set randomly without replacement into 2 subsamples: 
subTraining data (75% of the original Training data set) and subTesting data (25%). 

Our models will be fitted on the subTraining data set, and tested on the subTesting data. Once the most accurate model is choosen, it will be tested on the original Testing data set.

## Loading Data and Packages

The training data for this project are available here: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

```{r cache=TRUE}
library(RCurl)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)

set.seed(1234)

train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_data <- read.csv(text=getURL(train_url), na.strings=c("", "NA"))
test_data <- read.csv(text=getURL(test_url), na.strings=c("", "NA"))
```

## A look at the Data

The variable "classe" contains 5 levels: A, B, C, D and E. A plot of the outcome variable will allow us to see the frequency of each levels in the subTraining data set and compare one another.

```{r}
plot(train_data$classe, col="blue", main="Bar Plot of levels of the variable classe within the subTraining data set", xlab="classe levels", ylab="Frequency")
```

The first column of the data is just an index and is removed from training dataset. Also, the user and time information should not have any impact on qualitative assessment of barbell weight lifting and can be removed.

```{r}
train_data$X <- NULL
not_useful <- c("user_name", "raw_timestamp_part_1","raw_timestamp_part_2", "cvtd_timestamp")
for (col in not_useful) {
    train_data[, col] <- NULL
}
```

Many columns in the dataset have mostly missing values and won't play any role in the analysis. Removing those features from training and testing data.

```{r}
NAs_TRAIN <- apply(train_data,2,function(x) {sum(is.na(x))})
train_data <- train_data[,which(NAs_TRAIN == 0)]

NAs_TEST <- apply(test_data,2,function(x) {sum(is.na(x))})
test_data <- test_data[,which(NAs_TEST == 0)]
```

Also, removing features having one unique value or having few unique values relative to the number of samples or having ratio of frequency of the most common value to the frequency of second most common value as large.

```{r message=FALSE}
library(caret)
nzv <- nearZeroVar(train_data)
train_data <- train_data[-nzv]
test_data <- test_data[-nzv]
```

The final set of predictors used for classification are 

```{r}
names(train_data)
```

## Model

We build a random forest classifier to predict the action class. To measure the accuracy of the model, we do 10-fold cross validation with 80:20 split, on each fold, 80% of the data is used for training the random forest and remaining
20% is used for testing.

```{r cache=TRUE}
library(randomForest)
set.seed(1)
obs <- c()
preds <- c()
for(i in 1:10) {
    intrain = sample(1:dim(train_data)[1], size=dim(train_data)[1] * 0.8, replace=F)
    train_cross = train_data[intrain,]
    test_cross = train_data[-intrain,]
    rf <- randomForest(classe ~ ., data=train_cross)
    obs <- c(obs, test_cross$classe)
    preds <- c(preds, predict(rf, test_cross))
}
```

The confusion matrix for predictions on cross validation folds is given below.

```{r cache=TRUE}
conf_mat <- confusionMatrix(table(preds, obs))
conf_mat$table
```

The proposed model seems like a good classifier. The accuracy is `r conf_mat$overall[[1]] * 100`% and it misclassifies only few instances.

Finally, we train the random forest with whole dataset so that the classifier can be used to predict the class of an action, given the set of activity measurements.

```{r cache=TRUE}
model <- randomForest(classe ~ ., data=train_data)
```
